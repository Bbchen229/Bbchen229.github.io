<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chen&#39;s Homepage</title>
  
  <subtitle>Hello AI</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-09-30T16:45:05.204Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Chen jiayuan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Improved GCN for Text Classification [GNN]</title>
    <link href="http://example.com/2021/09/29/textGCN/"/>
    <id>http://example.com/2021/09/29/textGCN/</id>
    <published>2021-09-29T14:24:53.000Z</published>
    <updated>2021-09-30T16:45:05.204Z</updated>
    
    <content type="html"><![CDATA[<center><font size = 4> <strong>TextRGNN: Residual Graph Neural Networks for Text Classification</strong></font></center>]]></content>
    
    
      
      
    <summary type="html">&lt;center&gt;
&lt;font size = 4&gt; &lt;strong&gt;TextRGNN: Residual Graph Neural Networks for Text Classification&lt;/strong&gt;&lt;/font&gt;
&lt;/center&gt;
</summary>
      
    
    
    
    <category term="Research" scheme="http://example.com/categories/Research/"/>
    
    
    <category term="TextGCN" scheme="http://example.com/tags/TextGCN/"/>
    
  </entry>
  
  <entry>
    <title>word2vec</title>
    <link href="http://example.com/2021/09/29/word2vec/"/>
    <id>http://example.com/2021/09/29/word2vec/</id>
    <published>2021-09-28T16:10:00.000Z</published>
    <updated>2021-09-28T16:10:08.351Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>sort algorithm 1</title>
    <link href="http://example.com/2021/09/20/sort-1/"/>
    <id>http://example.com/2021/09/20/sort-1/</id>
    <published>2021-09-20T15:01:57.000Z</published>
    <updated>2021-09-28T16:05:07.653Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sorti">Sort(i)</h1><p>三种复杂度为<span class="math inline">\(O(n^2)\)</span>的排序算法:</p><ul><li>冒泡排序</li><li>选择排序</li><li>插入排序</li></ul><h2 id="bubble-sort">Bubble sort</h2><p>“一趟一趟来” <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span>(<span class="params">ls</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-i-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> ls[j] &gt; ls[j+<span class="number">1</span>]:</span><br><span class="line">                ls[j+<span class="number">1</span>],ls[j]=ls[j],ls[j+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span>(ls)</span><br></pre></td></tr></table></figure></p><h2 id="select-sort">Select sort</h2><p>&quot;一个一个排&quot; <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_sort</span>(<span class="params">ls</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-<span class="number">1</span>):</span><br><span class="line">        min_loc = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-<span class="number">1</span>-i):</span><br><span class="line">            <span class="keyword">if</span> ls[i+j]&lt;ls[min_loc]:</span><br><span class="line">                min_loc =i+j</span><br><span class="line">        ls[min_loc],ls[i] = ls[i],ls[min_loc]</span><br><span class="line">    <span class="built_in">print</span>(ls)</span><br></pre></td></tr></table></figure></p><h2 id="insert-sort">Insert sort</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_select</span>(<span class="params">ls</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(ls)):</span><br><span class="line">        j = i-<span class="number">1</span></span><br><span class="line">        tmp = ls[i]</span><br><span class="line">        <span class="keyword">while</span> j&gt;=<span class="number">0</span> <span class="keyword">and</span> ls[j]&gt;tmp:</span><br><span class="line">            ls[j+<span class="number">1</span>]=ls[j]</span><br><span class="line">            j-=<span class="number">1</span></span><br><span class="line">        ls[j+<span class="number">1</span>] = tmp</span><br><span class="line">    <span class="built_in">print</span>(ls)</span><br></pre></td></tr></table></figure><h1 id="sortii">Sort(ii)</h1><p>三种复杂度为<span class="math inline">\(O(nlogn)\)</span>的排序算法:</p><ul><li>快速排序</li><li>归并排序</li><li>堆排序</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;sorti&quot;&gt;Sort(i)&lt;/h1&gt;
&lt;p&gt;三种复杂度为&lt;span class=&quot;math inline&quot;&gt;\(O(n^2)\)&lt;/span&gt;的排序算法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;冒泡排序&lt;/li&gt;
&lt;li&gt;选择排序&lt;/li&gt;
&lt;li&gt;插入排序&lt;/li&gt;
&lt;/</summary>
      
    
    
    
    <category term="Leetcode" scheme="http://example.com/categories/Leetcode/"/>
    
    
    <category term="Data Structure" scheme="http://example.com/tags/Data-Structure/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression (python &amp; pytorch)</title>
    <link href="http://example.com/2021/08/25/dae%E7%9A%84%E5%89%AF%E6%9C%AC/"/>
    <id>http://example.com/2021/08/25/dae%E7%9A%84%E5%89%AF%E6%9C%AC/</id>
    <published>2021-08-25T15:21:47.000Z</published>
    <updated>2021-09-28T16:09:28.897Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    <category term="Preliminary AI" scheme="http://example.com/categories/Preliminary-AI/"/>
    
    
    <category term="ML" scheme="http://example.com/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>search algorithm</title>
    <link href="http://example.com/2021/08/25/test/"/>
    <id>http://example.com/2021/08/25/test/</id>
    <published>2021-08-25T14:42:55.000Z</published>
    <updated>2021-09-28T15:52:31.772Z</updated>
    
    <content type="html"><![CDATA[<h1 id="linear-search-and-binary-search">Linear Search and Binary Search</h1><h2 id="linear-search">Linear search</h2><p>Time complexity：<span class="math inline">\(O(n)\)</span> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_search</span>(<span class="params">ls,val</span>):</span></span><br><span class="line">    <span class="keyword">for</span> index,value <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        <span class="keyword">if</span> value == val:</span><br><span class="line">            <span class="keyword">return</span> index</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></p><h2 id="binary-search">Binary search</h2><p>Time complexity：<span class="math inline">\(O(log n)\)</span> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">ls,val</span>):</span></span><br><span class="line">    left = <span class="number">0</span>  <span class="comment">#左指针</span></span><br><span class="line">    right = <span class="built_in">len</span>(ls)-<span class="number">1</span>  <span class="comment">#右指针</span></span><br><span class="line">    <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">        mid = (left+right)//<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> ls[mid] == val:</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        <span class="keyword">elif</span> ls[mid]&lt;val:</span><br><span class="line">            left = mid+<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right = mid-<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;linear-search-and-binary-search&quot;&gt;Linear Search and Binary Search&lt;/h1&gt;
&lt;h2 id=&quot;linear-search&quot;&gt;Linear search&lt;/h2&gt;
&lt;p&gt;Time complexity：&lt;</summary>
      
    
    
    
    <category term="Leetcode" scheme="http://example.com/categories/Leetcode/"/>
    
    
    <category term="Data Structure" scheme="http://example.com/tags/Data-Structure/"/>
    
  </entry>
  
  <entry>
    <title>BERT</title>
    <link href="http://example.com/2021/08/16/test-my-site/"/>
    <id>http://example.com/2021/08/16/test-my-site/</id>
    <published>2021-08-16T14:58:35.000Z</published>
    <updated>2021-09-29T14:29:21.109Z</updated>
    
    <content type="html"><![CDATA[<h1 id="pre-training-of-deep-bidirectional-transformers-for-language-understanding">Pre-training of Deep Bidirectional Transformers for Language Understanding</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;pre-training-of-deep-bidirectional-transformers-for-language-understanding&quot;&gt;Pre-training of Deep Bidirectional Transformers for Lang</summary>
      
    
    
    
    <category term="Paper_daily" scheme="http://example.com/categories/Paper-daily/"/>
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Markdown语法</title>
    <link href="http://example.com/2021/08/16/hello-world/"/>
    <id>http://example.com/2021/08/16/hello-world/</id>
    <published>2021-08-16T14:25:40.470Z</published>
    <updated>2021-09-30T16:42:47.024Z</updated>
    
    <content type="html"><![CDATA[<p>由于Hexo博客的撰写需要用Markdown，虽然比Latex要简单点，但是平时用的比较少，这些杂七杂八的语法很难一下子全部记住，因此在这页博客中记录一下</p><h2 id="文字">文字</h2><h3 id="标题">标题</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="居中">居中</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;center&gt;这一行需要居中&lt;/center&gt;</span><br></pre></td></tr></table></figure><h3 id="字体">字体</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">**（）** 加粗</span><br><span class="line">*（）* 斜体</span><br><span class="line">～～（）～～ 删除线</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;font face= “黑体” color=red size=7&gt;字体设置&lt;/font&gt; #size 1-7，浏览器默认3</span><br></pre></td></tr></table></figure><h2 id="引用">引用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;这是引用文字</span><br></pre></td></tr></table></figure><h2 id="分割线">分割线</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">***</span><br></pre></td></tr></table></figure><h2 id="图片">图片</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![图片alt](图片地址 &#x27;&#x27;图片title&#x27;&#x27;)</span><br></pre></td></tr></table></figure><p>图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加</p><h2 id="链接">链接</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[超链接名](超链接地址 &quot;超链接title&quot;)</span><br></pre></td></tr></table></figure><h2 id="列表">列表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 列表内容</span><br><span class="line">+ 列表内容</span><br><span class="line">1. 列表内容</span><br></pre></td></tr></table></figure><h2 id="代码">代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">`代码内容`</span><br><span class="line">\``` (防止打不出加个\转义一下)</span><br><span class="line">  代码...</span><br><span class="line">  代码...</span><br><span class="line">  代码...</span><br><span class="line">\```</span><br></pre></td></tr></table></figure><h2 id="数学公式">数学公式</h2><p>公式、希腊字母、上标下标等基本语法与latex类似，可参考<a href="https://www.jianshu.com/p/a0aa94ef8ab2">markdown数学公式</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">正文中$...$</span><br><span class="line">单行显示$$...$$</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于Hexo博客的撰写需要用Markdown，虽然比Latex要简单点，但是平时用的比较少，这些杂七杂八的语法很难一下子全部记住，因此在这页博客中记录一下&lt;/p&gt;
&lt;h2 id=&quot;文字&quot;&gt;文字&lt;/h2&gt;
&lt;h3 id=&quot;标题&quot;&gt;标题&lt;/h3&gt;
&lt;figure class=&quot;</summary>
      
    
    
    
    <category term="杂七杂八" scheme="http://example.com/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>DAE for Action Quality Assessment(AQA)  [CV]</title>
    <link href="http://example.com/2020/09/25/dae/"/>
    <id>http://example.com/2020/09/25/dae/</id>
    <published>2020-09-25T15:21:47.000Z</published>
    <updated>2021-09-30T16:41:07.071Z</updated>
    
    <content type="html"><![CDATA[<p><font  size=5>Auto-Encoding Score Distribution Regression for Action Quality Assessment</font></p><p><em>Action quality assessment (AQA) from videos is a challenging vision task since the relation between videos and action scores is difficult to model. Thus, action quality assessment has been widely studied in the literature. Traditionally, AQA task is treated as a regression problem to learn the underlying mappings between videos and action scores. More recently, the method of uncertainty score distribution learning (USDL) made success due to the introduction of label distribution learning (LDL). But USDL does not apply to dataset with continuous labels and needs a fixed variance in training. In this paper, to address the above problems, we further develop Distribution Auto-Encoder (DAE). DAE takes both advantages of regression algorithms and label distribution learning (LDL). Specifically, it encodes videos into distributions and uses the reparameterization trick in variational auto-encoders (VAE) to sample scores, which establishes a more accurate mapping between videos and scores. Meanwhile, a combined loss is constructed to accelerate the training of DAE. DAE-MT is further proposed to deal with AQA on multi-task datasets. We evaluate our DAE approach on MTL-AQA and JIGSAWS datasets. Experimental results on public datasets demonstrate that our method achieves state-of- the-arts under the Spearman’s Rank Correlation: 0.9449 on MTL-AQA and 0.73 on JIGSAWS.</em></p><h2 id="aqa">AQA</h2><p>Action Quality Accessment (AQA) automatically scores the quality of actions by analyzing features extracted from videos and images. It’s different from conventional action recognition problem. In the past few years, much work has been devoted to different AQA tasks, such as healthcare, sports video analysis and many others.</p><h2 id="related-work">Related Work</h2><p>Parmar <em>et al.</em> [1] proposed C3D-SVR and C3D-LSTM to predict the score of the Olympic events. Additionally, incremental-label training method was introduced to train the LSTM model based on the hypothesis that the final score is an aggregation of the sequential sub-action scores.</p><p>Tang <em>et al.</em> noticed the underlying ambiguity of action scores and then proposed an improved approach: uncertainty-aware score distribution learning (USDL) [2] to address this problem. USDL is designed based on label distribution learning (LDL), a general learning paradigm to solve problems with uncertainty and answer how much each label describes the instance.</p><h2 id="methoddae">Method:DAE</h2><p><img src="/images/dae1.png" title="The pipeline of DAE architecture contains two segments: video features extraction network (orange) and label distribution encoding network (pink)." /></p><h3 id="video-feature-extraction">Video Feature Extraction</h3><p>The input video is divided into n small clips by down-sampling. Then the clips are sent into I3D ConvNets for extracting features. The final features are synthesized by three fully-connected layers.</p><h3 id="auto-encoder-for-distribution-learning">Auto-Encoder for Distribution Learning</h3><p>Compared with the regression-based method and the label distribution learning method, our approach combines the two methods’ characteristics comprehensively. The action features are encoded into score distribution, and the final result is sampled from the auto-encoders output. This architecture en- ables learning a continuous distribution without loss in training procedure and quantifies the uncertainty of action score with high accuracy.</p><p>The encoder uses a simple but quite an efficient neural network, namely multi-layered perceptrons (MLPs), to encode mean and variance simultaneously. The input 1024-dimensional feature vector x is encoded into the parameters <span class="math inline">\(μ(x)\)</span> and <span class="math inline">\(σ^2(x)\)</span> via a neural network.</p><p>We take the action score as a random variable. Treating the action score as a random variable, we need to learn its score distribution and then sample the predicted score from the obtained distribution. <span class="math display">\[p\left(y ; \mu(\boldsymbol{x}), \sigma^{2}(\boldsymbol{x})\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}(\boldsymbol{x})}} \exp \left(-\frac{(y-\mu(\boldsymbol{x}))^{2}}{2 \sigma^{2}(\boldsymbol{x})}\right)\]</span></p><p>To generate a sample from Gaussian distributed y as the predicted score and make full use of the two parameters in the score distribution at the same time, we invoke the reparameterization trick. According to reparameterization trick in VAE [3], assume that <span class="math inline">\(z\)</span> is a random variable, and <span class="math inline">\(z \sim q(z ; \phi), \phi\)</span> is its parameter. We can express <span class="math inline">\(z\)</span> as a deterministic variable, <span class="math inline">\(z=g(\epsilon ; \phi), \epsilon\)</span> is an auxiliary variable with independent marginal <span class="math inline">\(p(\epsilon)\)</span>, and <span class="math inline">\(g(\cdot ; \phi)\)</span> is a deterministic function parameterized by <span class="math inline">\(\phi\)</span>.<br /><span class="math display">\[y=\mu(\boldsymbol{x})+\epsilon * \sigma^{2}(\boldsymbol{x})\]</span></p><h2 id="experiments">Experiments</h2><p>We use Spearman’s rank correlation to measure the performance of our methods between the ground-truth and predicted score series. Spearman’s correlation is defined as: <span class="math display">\[\rho=\frac{\sum_{i}\left(p_{i}-\bar{p}\right)\left(q_{i}-\bar{q}\right)}{\sqrt{\sum_{i}\left(p_{i}-\bar{p}\right)^{2} \sum_{i}\left(q_{i}-\bar{q}\right)^{2}}}\]</span> <img src="/images/dae2.png" title="The results on JIGSAWS." /> <img src="/images/dae3.png" title="The results on MTL-AQA." /></p><p><img src="/images/dae4.png" title="Comparison of different distribution of different videos on MTL-AQA dataset." /></p><p>References (incomplete)<br />[1] What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment<br />[2] Uncertainty-aware score distribution learning for action quality assessment<br />[3] Auto-encoding variational bayes</p><p>Cooperate with zby (seu) supervisor: xyf (seu)<br /><a href="https://github.com/InfoX-SEU/DAE-AQA">Github link</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;font  size=5&gt;Auto-Encoding Score Distribution Regression for Action Quality Assessment&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Action quality assessment (AQA)</summary>
      
    
    
    
    <category term="Research" scheme="http://example.com/categories/Research/"/>
    
    
    <category term="AQA" scheme="http://example.com/tags/AQA/"/>
    
  </entry>
  
</feed>
