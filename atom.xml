<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chen&#39;s Homepage</title>
  
  <subtitle>Hello AI</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-10-27T16:57:37.967Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Chen jiayuan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Multi-Label Image Recognition with Graph Convolutional Networks [CVPR2019]</title>
    <link href="http://example.com/2021/10/26/pd5/"/>
    <id>http://example.com/2021/10/26/pd5/</id>
    <published>2021-10-26T15:25:47.000Z</published>
    <updated>2021-10-27T16:57:37.967Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1904.03582">Multi-Label Image Recognition with Graph Convolutional Networks</a><br />Code: <a href="https://github.com/chenzhaomin123/ML_GCN">link</a></p><p>针对多标签图像识别 (multi-label image recognition) 问题，旷视研究院提出一种基于图卷积网络的模型取得了良好的表现，该模型包含一个CNN的图像特征提取模块和一个图卷积网络进行标签间关系提取模块。</p><h2 id="intro">Intro</h2><p>对于多标签图像的识别问题，传统的方法往往是对每个标签进行孤立的二分类，即预测每个物体是否出现。基于概率图模型或RNN模型的方法则考虑显式的建模标签之间的依赖关系。也有方法将图像区域划分后考虑区域间的局部相关性，从而隐式的建模标签相关性。本文提出的基于GCN的端到端模型将标签的表示映射到相互独立的对象分类器上。</p><h2 id="related-work">Related Work</h2><p>最简单的多标签识别方法就是为每个标签独立训练一个二分类器，这种模型没有考虑标签之间的关系。当数据集中可能的标签数量增长时，可能的标签组合就会指数级增长（当一个数据集包含20个标签，则标签组合就有<span class="math inline">\(2^{20}\)</span>种。基于RNN、LSTM之类的模型将标签嵌入为向量，从而发掘标签间的相关性。<br />本文提出的模型将多标签构建为有向图，借助GCN在标签间的信息传播来学习图像标签间依赖、共现关系，并实现端到端训练。</p><h2 id="framework">Framework</h2><p><img src="/images/pd5/2.png" title="模型框架" /></p><h3 id="图像特征提取">图像特征提取</h3><p>论文用CNN进行图像特征提取，具体为ResNet-101的网络结构，输入图像<span class="math inline">\(I\)</span>，经过cnn和global max-pooling后得到2048维图像特征。 <span class="math display">\[\boldsymbol{x}=f_{\mathrm{GMP}}\left(f_{\mathrm{cnn}}\left(\boldsymbol{I} ; \theta_{\mathrm{cnn}}\right)\right) \in \mathbb{R}^{D}\]</span></p><h3 id="图卷积">图卷积</h3><p>卷积模块与最基本的卷积相同，如下式 <span class="math display">\[\boldsymbol{H}^{l+1}=h\left(\widehat{\boldsymbol{A}} \boldsymbol{H}^{l} \boldsymbol{W}^{l}\right)\]</span> 我们主要关注如何构图，在这一方面，本文的idea似乎有些超脱CV领域。模型针对图片数据集构建图，图中的节点为数据中的标签，并使用word embedding（pre-trained glove）对节点特征进行初始化。<br />而对于图的边，也对应图卷积中的矩阵<span class="math inline">\(\boldsymbol{A}\)</span>（文中称其为相关系数矩阵），模型使用条件概率<span class="math inline">\(P\left(L_{j} \mid L_{i}\right)\)</span>进行建模，已期获得标签相关性信息。 <img src="/images/pd5/3.png" /> 具体而言，论文统计了数据集中的标签对的共现次数，然后构建共现矩阵，并设定一个阈值来进行二值化处理，借此过滤噪声边。 <img src="/images/pd5/1.png" title="基于多标签构建有向图" /></p><p>借助模型框架图可以看到，模型中图卷积模块起的是类似辅助分类器的作用，图中每个标签节点就是该标签的一个二分类器，将基于整个数据集训练的分类器<span class="math inline">\(\boldsymbol{W} \in \mathbb{R}^{C \times D}\)</span>与图像的特征<span class="math inline">\(x \in \mathbb{R}^{D}\)</span>进行点积，得到<span class="math inline">\(\boldsymbol{y} \in \mathbb{R}^{C}\)</span>（C表示标签的总数）。图卷积利用的信息也只有图的边，也就是标签的共现，而后借助图卷积与图像特征提取进行共同训练，得到标签之间关系的隐式表示，最终推动更准确的多标签识别。</p><h2 id="实验">实验</h2><p><img src="/images/pd5/4.png" title="实验结果—非常不错 XD" /> 不过在尝试复现该模型时，本人试验了几个数据集似乎始终无法到达论文中的结果。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.03582&quot;&gt;Multi-Label Image Recognition with Graph Convolutional Networks&lt;/a&gt;&lt;br /&gt;
Code: &lt;a href=&quot;https</summary>
      
    
    
    
    <category term="Paper_daily" scheme="http://example.com/categories/Paper-daily/"/>
    
    
    <category term="CV-GNN" scheme="http://example.com/tags/CV-GNN/"/>
    
  </entry>
  
  <entry>
    <title>Multi-hop Question Generation with Graph Convolutional Network [Arxiv]</title>
    <link href="http://example.com/2021/10/24/pd6/"/>
    <id>http://example.com/2021/10/24/pd6/</id>
    <published>2021-10-24T15:56:42.000Z</published>
    <updated>2021-10-27T17:48:33.014Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/2010.09240.pdf">Multi-hop Question Generation with Graph Convolutional Network</a><br />Code: <a href="https://github.com/HLTCHKUST/MulQG">link</a></p><h2 id="background">Background</h2><p>问题生成(QG)是一个从给定的上下文自动生成问题或答案的任务，而多跳问题生成 (Multi-hop Question Generation) 需要从多个不同的段落中推理生成与答案相关的问题。QG可以应用于教育系统，也可以结合QA模型作为双重任务来增强QA系统的推理能力。对于多跳问题生成，核心问题在于如何连接多个段落间的零散的信息以及答案。</p><p><img src="/images/pd6/1.png" title="多跳问题生成" /></p><h2 id="模型">模型</h2><p><img src="/images/pd6/2.png" title="模型框架" /></p><h3 id="multi-hop-encoder">Multi-hop Encoder</h3><p>对于输入的文本段落和答案，先分割成word-level的token，并分别用pre-trained Glove进行embedding，并在文本的token embedding中加入答案 embedding tag。对于得到的token embedding 输入到LSTM-RNN中学习初步的上下文相关的representation，再输入到Encoder中，模型的Encoder包括三个部分:</p><ul><li><p>Answer-aware context encoder 这一部分参考了阅读理解中的co-attention reasoning机制: <span class="math display">\[\begin{aligned}S &amp;=C_{0}^{T} A_{0} \in R^{n \times m} \\S^{\prime} &amp;=\operatorname{softmax}(S) \in R^{n \times m} \\S^{\prime \prime} &amp;=\operatorname{softmax}\left(S^{T}\right) \in R^{m \times n} \\A_{0}^{\prime} &amp;=C_{0} \cdot S^{\prime} \in R^{d \times m} \\\tilde{C}_{1} &amp;=\left[A_{0} ; A_{0}^{\prime}\right] \cdot S^{\prime \prime} \in R^{2 d \times n}\\C_{1} &amp;=\operatorname{BiLSTM}\left(\left[\tilde{C}_{1} ; C_{0}\right]\right) \in R^{d \times n}\end{aligned}\]</span> 相关性矩阵S表示答案与上下文的相关性，整个过程比较复杂，这一模块的有效性在阅读理解任务中被验证，大致操作即将答案与文本计算attention后生成新的“答案”而后同样进行一遍相关性计算，最后输入Bi-LSTM中。</p></li><li><p>GCN-based entity-aware answer encoder 将上述encoder得到的embedding输入到GCN中进行多跳信息的嵌入。 <img src="/images/pd6/3.png" title="GCN-based entity-aware answer encoder" /> 图中的节点为文本中的命名实体（由BERT自动化提取），如果实体对在同一句子中，则为它们创建边。将上面Answer-aware context encoder 的结果结合到多跳图卷积中，并最终和图的结果结合，输入到Bi-attention模型，进一步得到token的representations <span class="math display">\[A_{1}=\text { BiAttention }\left(A_{0}, E_{M}\right)\]</span></p></li><li><p>Gated encoder reasoning layer 将前面得到的结果输入到门控网络进行特征融合，进行特征保留或遗忘，得到最终的Encoder结果。</p></li></ul><h3 id="maxout-pointer-decoder">Maxout Pointer Decoder</h3><p>模型采用单向LSTM作为解码器，而Maxout pointer这一模块也并不是由作者提出的，而是参考了他人的模型，用这一模块减少生成结果中的重复项。</p><h2 id="实验">实验</h2><p>实验部分，作者分别做了与现有multi-hop QG模型对比以及消融实验，取得了SOTA结果，并且证明了框架中每个模块的意义。 <img src="/images/pd6/4.png" title="纵向对比" /> <img src="/images/pd6/5.png" title="消融实验" /></p><h2 id="总结">总结</h2><p>本文提出的框架总体来说比较复杂。往牛了说可以理解为整个框架模拟了人类的问题生成的过程，包括整体文本和答案的阅读，进行大概了解，而后对文本和答案中的实体进行关注，并寻找他们的联系，最后在生成问题时确定核心和次要信息，生成相关的问题。不过事实上整个框架就是对几个现有模型中的部分模块进行组装，类似“搭积木”的过程。而新加入的multi-hop图卷积部分整体方法也不具有很亮点的想法，从消融实验结果中也可以看出这一模块对最终结果的提升也并不是很明显。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.09240.pdf&quot;&gt;Multi-hop Question Generation with Graph Convolutional Network&lt;/a&gt;&lt;br /&gt;
Code: &lt;a href=&quot;ht</summary>
      
    
    
    
    <category term="Paper_daily" scheme="http://example.com/categories/Paper-daily/"/>
    
    
    <category term="QA" scheme="http://example.com/tags/QA/"/>
    
  </entry>
  
  <entry>
    <title>2021 MAXP命题赛 基于DGL的图机器学习任务</title>
    <link href="http://example.com/2021/10/23/maxp/"/>
    <id>http://example.com/2021/10/23/maxp/</id>
    <published>2021-10-23T07:33:06.000Z</published>
    <updated>2021-10-26T12:52:51.527Z</updated>
    
    <content type="html"><![CDATA[<p>使用<a href="https://www.dgl.ai/">Deep Graph Library (DGL)</a>进行图节点分类任务，使用的图数据是基于微软学术文献生成的论文关系图，其中的节点是论文，边是论文间的引用关系。整个图包括约150万个节点，2000万条边。节点包含300维的特征，来自论文的标题和摘要等内容。节点属于约50个类别。<br />比赛地址: <a href="https://biendata.xyz/competition/maxp_dgl/">MAXP</a></p><p><img src="/images/maxp/1.png" title="比赛数据集" /></p><h2 id="数据预处理">数据预处理</h2><p>根据所给的数据集，我们需要读取节点及其对应的特征，以及边。根据论文id构建对应的节点id，并分配他们的特征和类别。读取边之后发现存在部分论文没有出现在论文数据中，这部分的节点id分配到最后，这类论文没有类别和特征，这些点的特征可以选择用邻节点特征均值进行赋值。节点特征使用Numpy保存为.npy格式，方便后续读取。<br />对train文件中的数据进行Train/Valid分割，用于模型评估（9:1），将train/valid/test节点id和labels等数据保存为二进制文件方便快速读取 <img src="/images/maxp/3.png" /></p><h2 id="图构建">图构建</h2><p>根据上面的到的原论文id-引用论文id以及他们对应的节点id，借助DGL包构建论文引用关系图。 <img src="/images/maxp/2.png" title="构图" /> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">g = dgl.graph((u,v))</span><br><span class="line">g.nodes() <span class="comment">#获取节点id</span></span><br><span class="line">g.edges() <span class="comment">#获取边对应的节点（输出的是两个tensor）</span></span><br><span class="line">g.ndata(<span class="string">&#x27;feature&#x27;</span>) <span class="comment">#访问节点属性</span></span><br><span class="line">g.edata <span class="comment">#访问边属性</span></span><br></pre></td></tr></table></figure></p><h2 id="model_baseline">Model_baseline</h2><p>预处理和构图之后，我们模型输入的数据包括： <img src="/images/maxp/4.png" /></p><p>竞赛的baseline包括三个模型：</p><ul><li>graphsage</li><li>graphconvolution</li><li>graphattention</li></ul><p>其中各个网络由DGL.nn模块调库搭建。经过初步调参后发现网络深度为3层时三个模型结果最好，其中graphsage表现最好，在验证集上准确率接近54。 <img src="/images/maxp/5.png" title="可视化效果" /></p><h2 id="proposed-model">Proposed model</h2><p>数据中的节点特征已经给定，因此只能改变模型的网络结构，我参考了2020 acl的论文：Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks 所用的网络架构，具体采用的是三层图卷积后连接一层图注意力，并在图卷积与attention直接增加了skip-connection。在验证集上的到准确率为55+，目前排行榜上前10，后续将会做进一步调参来得到更好的结果。<br />另外，根据给定的特征直接使用MLP等前向传播网络虽然无法利用引用信息，但可以用来辅助最终的分类。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;使用&lt;a href=&quot;https://www.dgl.ai/&quot;&gt;Deep Graph Library (DGL)&lt;/a&gt;进行图节点分类任务，使用的图数据是基于微软学术文献生成的论文关系图，其中的节点是论文，边是论文间的引用关系。整个图包括约150万个节点，2000万条边。节</summary>
      
    
    
    
    <category term="Project" scheme="http://example.com/categories/Project/"/>
    
    
    <category term="Competition" scheme="http://example.com/tags/Competition/"/>
    
  </entry>
  
  <entry>
    <title>A Survey of Graph Neural Networks in Natural Language Processing [Arxiv]</title>
    <link href="http://example.com/2021/10/18/gnn-nlp/"/>
    <id>http://example.com/2021/10/18/gnn-nlp/</id>
    <published>2021-10-18T05:58:53.000Z</published>
    <updated>2021-10-26T15:36:48.929Z</updated>
    
    <content type="html"><![CDATA[<p>截止2021年初，关于现有的图神经网络应用在自然语言处理领域的综述<br />link: <a href="https://arxiv.org/abs/2106.06090">Graph Neural Networks for Natural Language Processing: A Survey</a></p><p>另外，本篇博客还包含另外几篇图相关的综述性文章内容：<br />Graph Representation Learning<br />Geometric Deep Learning</p><p>对于图的机器学习，非常容易想到的就是节点分类，边预测、以及图层级的分类等。对于传统的NLP问题，我们将输入的文本序列表示为图结构时，就可以借助图深度学习技术进行处理。整篇综述根据这一思路从图构造、图表示学习、基于图的Encoder-Decoder模型三方面进行介绍。</p><h2 id="图构造">图构造</h2><p>对于AI处理的数据类型，大概可以分类3类：Euclidean Structure、Sequence Structure、Graph Structure。<br />Eucildean data比如图，Sequence data如文本，这类数据都有一个特点：规则，即排列整齐；而图结构这类非欧几何数据，样本是不规则的，每个样本的邻居节点数量都是不同的，因此图像中的卷积操作就无法在图结构中应用。</p><p>针对输入的数据，包括文本、树等，我们根据一定的规则自动化构造构建不同类型的图，如无向图、有向图、多关系图、异构图并使用特点的GNN结构来进行学习。</p><h3 id="静态图构建">静态图构建</h3><p>利用规则或现有的关系解析工具在文本预处理时构造图结构，常见的静态图构建有：</p><ul><li><p>Dependency Graph<br />依赖图可以用于捕捉给定句子中两个主语之间的关系。对于给定的句子，可以借助现有的解析工具包得到dependency parsing tree，而后抽取出依赖关系，构建dependency graph</p></li><li><p>Constituency Graph<br />语言学中constituency relation指符合短语结构语法的关系，比如主语NP和谓语VP的关系 <img src="/images/pd3_1.png" /></p></li><li><p>Information Extraction Graph<br />IE Graph抽取出文本中跨越不同句的结构化的信息。构建IE图首先要提取三元组，而后通过不同三元组间共同参数来确定相同含义的实体进行合并，从而减少节点的数量，消除模糊性。 <img src="/images/pd3_2.png" /></p></li><li><p>Knowledge Graph<br />知识图谱能捕获实体以及关系，被广泛用于推理、关系抽取等任务中。知识图谱可以作为文本到embedding之间的一个精练且可解释的中间表示。KG可以表示为 <span class="math inline">\(\mathcal{G}(\mathcal{V}, \mathcal{E})\)</span>，由三元组<span class="math inline">\(\left(e_{1}, r e l, e_{2}\right)\)</span>。KG在不同的下游任务中起不同的作用，如机器翻译可以用于数据增强，阅读理解中用于构建子图。 <img src="/images/pd3_3.png" /></p></li><li><p>Co-occurrence Graph</p></li></ul><p>共现关系描述了两个词在固定大小的上下文窗口内共现的频率，而后单词和词与词间共现频率构建图。<br />除了上述几类图构建方法外，针对具体的任务还有很多不同的图构造方法。</p><h3 id="动态图构建">动态图构建</h3><p>静态图可以将数据的部分先验知识编码到图中，但是这需要大量的人力试验以及领域专业知识，且容易包含噪声。另外，静态图的构建是基于构建者自身的经验，得到的并不一定是对于某一下游任务最优的图。<br />而动态图则是动态学习图结构（加权邻接矩阵），图构造模块和后续图表示学习一起针对下游任务联合优化。图结构学习也是机器学习领域研究的热点问题 <img src="/images/pd3_4.png" alt="动态图构建方法" /></p><p><strong>Graph similarity metric learning</strong><br />图结构学习可以转化为节点相似度度量问题 (相似度矩阵<span class="math inline">\(S\)</span>)，对于相似度度量函数，可以分为两类：</p><ul><li>基于节点嵌入的相似度度量学习</li><li>基于结构感知的相似度度量学习</li></ul><p><em>基于节点嵌入的相似度函数</em>通过计算嵌入空间中节点的成对相似度来学习加权邻接矩阵。常见的度量函数包括基于注意力的度量函数和基于余弦的度量函数。 <span class="math display">\[S_{i, j}=\operatorname{ReLU}\left(\vec{W} \vec{v}_{i}\right)^{T} \operatorname{ReLU}\left(\vec{W} \vec{v}_{j}\right)\]</span> 上式为基于注意力的度量函数，<span class="math inline">\(\vec{W}\)</span>为可学习的权重。类似的，基于cosine的度量函数为： <span class="math display">\[\begin{aligned}S_{i, j}^{p} &amp;=\cos \left(\vec{w}_{p} \odot \vec{v}_{i}, \vec{w}_{p} \odot \vec{v}_{j}\right) \\S_{i, j} &amp;=\frac{1}{m} \sum_{p=1}^{m} S_{i j}^{p}\end{aligned}\]</span></p><p><em>基于结构感知的相似性函数</em>在节点信息之外还考虑了边的信息，如 <span class="math display">\[S_{i, j}^{l}=\operatorname{softmax}\left(\vec{u}^{T} \tanh \left(\vec{W}\left[\vec{h}_{i}^{l}, \vec{h}_{j}^{l}, \vec{v}_{i}, \vec{v}_{j}, \vec{e}_{i, j}\right]\right)\right)\]</span> 其中<span class="math inline">\(\vec{v}_{i}\)</span> 代表节点i的embedding， <span class="math inline">\(i\vec{e}_{i, j}\)</span> 代表边的embedding $ _{i}^{l}$ 代表节点i在GNN中第i层的embedding， <span class="math inline">\(\vec{u}\)</span>和<span class="math inline">\(\vec{W}\)</span> 是可训练的权重。</p><p><strong>Graph sparsification</strong><br />现实世界中大多数的图都是稀疏图，而通过相似度度量函数会得到任意两个节点之间的边，最终生成一个全连通图，这会极大增大开销，并引入噪声，因此需要进行图稀疏化处理。常用的方法包括取k个相似度最高的邻节点，或者给节点间的相似度设定一个阈值。</p><p>另外，静态图和动态图也可以结合起来，既可以加速训练，提高稳定性，也能提高下游任务的表现 <span class="math display">\[\widetilde{A}=\lambda L^{(0)}+(1-\lambda) \mathrm{f}(A)\]</span> 上式中<span class="math inline">\(L^{(0)}\)</span>表示静态图结构，<span class="math inline">\(\mathrm{f}(A)\)</span>表示可学习的动态图结构。</p><h2 id="图表示学习">图表示学习</h2><p>由于图的类型多种多样，如同构图、异构图、多关系图等等，这些不同的图上进行图表示学习的具体模型或有出入，但总体的步骤和思路基本类似。下面介绍的图表示学习方法是基于同构图，且节点与节点之间仅有一条无向边。</p><h3 id="basic-gnn">Basic GNN</h3><p>图神经网络对图中的节点进行embedding，并根据需求给出最终的node embedding或graph embedding。图神经网络的特征传播总体可以分成两个步骤，包括聚合-Aggregation和更新-Update。 <span class="math display">\[\mathbf{m}_{\mathcal{N}(u)}=\operatorname{AGGREGATE}^{(k)}\left(\left\{\mathbf{h}_{v}^{(k)}, \forall v \in \mathcal{N}(u)\right\}\right)\]</span> <span class="math display">\[\operatorname{UPDATE}\left(\mathbf{h}_{u}, \mathbf{m}_{\mathcal{N}(u)}\right)=\sigma\left(\mathbf{W}_{\text {self }} \mathbf{h}_{u}+\mathbf{W}_{\operatorname{neigh}} \mathbf{m}_{\mathcal{N}(u)}\right)\]</span></p><p>其中<span class="math inline">\(\mathcal{N}(u)\)</span>表示节点<span class="math inline">\(u\)</span>的邻节点，<span class="math inline">\(\mathbf{h}_{u}\)</span>则代表节点特征，<span class="math inline">\(\mathbf{W}\)</span>为可学习的权重矩阵。</p><h3 id="aggregation">Aggregation</h3><p>聚合操作将节点的邻节点特征进行汇总，常用的方法包括：</p><ul><li><p>Normalization：最基本的聚合方法就是对邻节点embedding求平均，并针对节点的度进行归一化 <span class="math display">\[\mathbf{m}_{\mathcal{N}(u)}=\frac{\sum_{v \in \mathcal{N}(u)} \mathbf{h}_{v}}{|\mathcal{N}(u)|}\]</span></p></li><li>Pooling：基于MLP这类的置换不变(permutation invariant)网络进行聚合，通用的pooling aggregator可以表示为： <span class="math display">\[\mathbf{m}_{\mathcal{N}(u)}=\operatorname{MLP}_{\theta}\left(\sum_{v \in N(u)} \operatorname{MLP}_{\phi}\left(\mathbf{h}_{v}\right)\right)\]</span> 另一种Janossy pooling则是赋予邻节点一个次序，并使用对于时序敏感的函数进行聚合 <span class="math display">\[\mathbf{m}_{\mathcal{N}(u)}=\operatorname{MLP}_{\theta}\left(\frac{1}{|\Pi|} \sum_{\pi \in \Pi} \rho_{\phi}\left(\mathbf{h}_{v_{1}}, \mathbf{h}_{v_{2}}, \ldots, \mathbf{h}_{v_{|\mathcal{N}(u)|}}\right)_{\pi_{i}}\right)\]</span></li><li><p>Attention： 对邻节点分配不同的权重，权重可以基于邻节点的embedding，也可以基于边的权值 <span class="math display">\[\mathbf{m}_{\mathcal{N}(u)}=\sum_{v \in \mathcal{N}(u)} \alpha_{u, v} \mathbf{h}_{v}\]</span> <span class="math display">\[\alpha_{u, v}=\frac{\exp \left(\mathbf{a}^{\top}\left[\mathbf{W h}_{u} \oplus \mathbf{W h}_{v}\right]\right)}{\sum_{v^{\prime} \in \mathcal{N}(u)} \exp \left(\mathbf{a}^{\top}\left[\mathbf{W h}_{u} \oplus \mathbf{W h}_{v^{\prime}}\right]\right)}\]</span></p></li></ul><h3 id="updates">Updates</h3><p>在经过多层图神经网络后，某些节点自身的特性会因为不断聚合邻节点的信息而淡化或被抹去，这就导致深度图神经网络的over-smoothing问题。<br />为缓解over-smoothing问题的一些技巧，比如Concatenation和Skip-Connections等在节点信息聚合后的更新操作入手。 <span class="math display">\[\text { UPDATE }_{\text {concat }}\left(\mathbf{h}_{u}, \mathbf{m}_{\mathcal{N}(u)}\right)=\left[\text { UPDATE }_{\text {base }}\left(\mathbf{h}_{u}, \mathbf{m}_{\mathcal{N}(u)}\right) \oplus \mathbf{h}_{u}\right]\]</span></p><h3 id="graph-convolutional-networks-gcn">Graph Convolutional Networks (GCN)</h3><p>图卷积就如同CV中的卷积，被提出后受到了广泛关注和研究。欧氏空间中的离散卷积我们很好理解，而对于非欧数据中的卷积，它的提出流程可以概括为：图信号处理GSP学者提出图的Fourier Transformation，进而得到Graph convolution，从而拓展到神经网络的图卷积网络。</p><p>图的卷积定义在spectral domain，相应的邻接矩阵<span class="math inline">\(A\)</span>用图的Laplacian 矩阵<span class="math inline">\(L\)</span>替代。<span class="math inline">\(L = D - A\)</span>，<span class="math inline">\(D\)</span>为度矩阵。把传统的傅里叶变换以及卷积迁移到Graph上, 核心工作就是把拉普拉斯算子的特征函数 <span class="math inline">\(e^{-i \omega t}\)</span> 变为Graph对应的拉普拉斯矩阵的特征向量。这其中具体的推导过程在此不再赘述。基本的GCN中第k层可以写为下式： <span class="math display">\[\mathbf{H}^{(k)}=\sigma\left(\tilde{\mathbf{A}} \mathbf{H}^{(k-1)} \mathbf{W}^{(k)}\right)\]</span> 其中<span class="math inline">\(\tilde{\mathbf{A}}=(\mathbf{D}+\mathbf{I})^{-\frac{1}{2}}(\mathbf{I}+\mathbf{A})(\mathbf{D}+\mathbf{I})^{-\frac{1}{2}}\)</span>，是拉普拉斯矩阵的一个变形形式。</p><h3 id="graphsage">GraphSAGE</h3><p>GraphSAGE这一图模型是归纳式 (inductive) 学习。不同于之前的transducer模型，GraphSAGE的目标不是学习到每个节点的embedding，而是学习生成embedding的聚合函数。 <img src="/images/pd3_5.png" /> 整个框架如上图所示，包括采样、聚合、预测三个步骤。在采样时会选择恒定数量的邻节点，且不仅仅选择1-hop的节点，而是考虑multi-hop。</p><h2 id="基于图的encoder-decoder模型">基于图的Encoder-Decoder模型</h2><p>Encoder-Decoder是深度学习模型中非常常见的架构，因此到了图深度学习领域，图到树、graph-graph等模型也应运而生。</p><h3 id="graph-to-sequence-model">Graph-to-Sequence Model</h3><p>这类模型通常用GNN作为Encoder，RNN/Transformer作为Decoder。此外，这类模型中多使用CNN进行节点特征初始化，用于捕捉GNN不敏感的连续词的潜在信息。这类模型在多关系图或异构图的处理上有所局限。</p><h3 id="graph-to-tree-model">Graph-to-Tree Model</h3><p>类似端到端的模型，在NLP任务中，树也具有很强大的表达能力。由于树广义上来讲也是一种图，因此Graph-Tree这类模型的核心在于借助self-attention进行获取局部邻节点的权重，再由decoder 生成包含语义的tree结构。这类模型的应用比如语义解析、数学应用问题（模型输出为由树来表示的方程）。</p><h3 id="graph-to-graph-model">Graph-to-Graph Model</h3><figure><img src="/images/pd3_6.png" alt="图的生成式模型(VAE)" /><figcaption>图的生成式模型(VAE)</figcaption></figure><h2 id="补充">补充</h2><h3 id="图神经网络在nlp中的下游任务">图神经网络在NLP中的下游任务</h3><p>已有的基于图相关技术的NLP任务包括自然语言生成、机器翻译、情感分类、文本分类、知识图谱补全、信息抽取（命名实体识别、关系抽取）、自然语言推理、解数学问题（文本）等</p><h3 id="关于图的semi-supervised">关于图的semi-supervised</h3><p>对于监督学习，如一个分类问题，我们的样本需要满足i.i.d assumption：样本之间是独立同分布的（不然还需要建模样本之间的联系）。然而在图结构上做诸如节点分类问题时，节点之间相互联系，且这些联系在节点分类中起到了重要的作用。因此基于图的很多深度学习是semi-supervised。这意味着在训练图模型时，我们利用了测试节点的信息，但不包括label。</p><h3 id="深度学习模型的迁移">深度学习模型的迁移</h3><p>近几年随着图神经网络的兴起，许多人都涌向这块处女地，深度学习模型中的一些经典思想和模型也被迁移到图相关的模型中，比如基于self-attention的GAT、GraphGAN、Graph Transformer等。另外，在NLP落地的经典搜索、广告、推荐算法中，图神经网络也被广泛应用。<br /><a href="https://arxiv.org/abs/1711.08267">GraphGAN: Graph Representation Learning with Generative Adversarial Nets</a><br /><a href="https://arxiv.org/pdf/1911.07470.pdf">Graph Transformer for Graph-to-Sequence Learning</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;截止2021年初，关于现有的图神经网络应用在自然语言处理领域的综述&lt;br /&gt;
link: &lt;a href=&quot;https://arxiv.org/abs/2106.06090&quot;&gt;Graph Neural Networks for Natural Language Proce</summary>
      
    
    
    
    <category term="Paper_daily" scheme="http://example.com/categories/Paper-daily/"/>
    
    
    <category term="GNN" scheme="http://example.com/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>Vocabulary Learning via Optimal Transport for Neural Machine Translation [ACL2021]</title>
    <link href="http://example.com/2021/10/10/pd2/"/>
    <id>http://example.com/2021/10/10/pd2/</id>
    <published>2021-10-10T10:22:13.000Z</published>
    <updated>2021-10-26T15:36:20.914Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/2012.15671.pdf">Vocabulary Learning via Optimal Transport for Neural Machine Translation</a><br />ACL2021 Best paper Code: <a href="https://github.com/Jingjing-NLP/VOLT">link</a></p><p>这篇也就是被ICLR2021拒了后被评为ACL2021 best paper的文章，来自字节跳动的AI Lab。</p><h2 id="related-work">Related Work</h2><h3 id="subword-model">Subword model</h3><p>英文中传统分词方法基于空格进行tokenization。但这一方法面临OOV (Out Of Vocabulary)问题和同一单词的不同形态造成的冗余。因此如今BERT等模型多使用Subword模型，它的划分粒度介于词与字符之间。主流的(指某些中文网站上有博客介绍的）Subword model有Byte Pair Encoding (BPE), WordPiece和Unigram Language Model。</p><h3 id="byte-pair-encodingbpe">Byte-Pair-Encoding(BPE)</h3><p>&quot;Neural machine translation of rare words with subword units.&quot;arXiv preprint arXiv:1508.07909(2015).<br />BPE算法被用于处理NMT (Neural Machine Translation)任务中的OOV问题。<br />BPE是一种自下而上的压缩算法。将单词作为单词片段处理（word pieces），以便于处理未出现单词。</p><blockquote><p>we adopt BPE generated tokens as the token candidates.</p></blockquote><p>论文提出的算法要先用BPE...</p><h2 id="概要">概要</h2><p>机器翻译中，token vocabulary对最终结果会产生很大的影响。论文研究了词表的评价指标以及如何不通过训练直接找到最优的词表。文章的主要内容包括 1. 从信息论角度分析词表的作用 2.借助Optimal transport来找到最佳token词典 3. 更小的词表but更高的BLEU。</p><h2 id="intro">Intro</h2><p>词汇量（vocabulary size）会影响机器翻译任务的绩效，而通过遍历搜索来寻找最优的词汇量需要极高的计算开销，因此现有的研究大多采用统一的大小，如30k-40k。BPE通过选择频率最高的sub-words做为词典的token以进行数据压缩，以此减少熵。</p><p>语料熵随着词汇量的增加而减少，有利于模型学习。另一方面，过多的字符会导致字符稀疏化，这会损害模型学习。本文通过同时考虑熵和词汇量大小来探索自动词汇化，需要找到一个合适的目标函数来同时优化它们。其次，假设给出了适当的度量，由于指数搜索空间（<span class="math inline">\(2^N\)</span>)，解决这种离散优化问题仍然具有挑战性。</p><p>针对上述问题，论文提出VOcabulary Learning approach via optimal Transport, VOLT——最优传输的词汇学习方法</p><p>总的来说，论文的目标是1.得到“简洁而不臃肿”的词汇表 —— entropy-size trade off 2. 优化搜索过程。</p><h2 id="marginal-utility-of-vocabularization-muv">Marginal Utility of Vocabularization (MUV)</h2><p>借用经济学中的边际效应的概念，以词汇的边际效应（MUV）作为衡量标准， 然后将目标转向在可处理的时间复杂度中最大化 MUV。 <img src="/images/pd2_3.png" title="vocabulary的边际效益（没有显示给出MUV）" /></p><p>在经济学中，边际效应用于平衡收益和成本，因此论文使用 MUV 来平衡熵（收益）和词汇量（成本）。也就是从成本（大小）的增加中获得多大的收益（熵）。</p><p><img src="/images/pd2_1.png" title="MUV 与三分之二翻译任务的下游性能相关" /></p><h3 id="definition-of-muv">Definition of MUV</h3><p>MUV 表示熵对大小的负导数 <span class="math display">\[\mathcal{M}_{v(k+m)}=\frac{-\left(\mathcal{H}_{v(k+m)}-\mathcal{H}_{v(k)}\right)}{m}\]</span> 其中 <span class="math inline">\(v(k), v(k+m)\)</span> 是两个分别带有 <span class="math inline">\(k\)</span> 和 <span class="math inline">\(k+m\)</span> 个字符的词汇。<span class="math inline">\(\mathcal{H}_{v}\)</span> 表示词汇表 <span class="math inline">\(v\)</span> 语料库的樀，它由字符樀的总和定义。用字符的平均长度对熵进行归一化来避免字符长度的影响。最终的熵定义为： <span class="math display">\[\mathcal{H}_{v}=-\frac{1}{l_{v}} \sum_{j \in v} P(j) \log P(j)\]</span> <span class="math inline">\(P(i)\)</span> 是训练语料库中token <span class="math inline">\(i\)</span> 的相对频率, <span class="math inline">\(l_{v}\)</span> 是词汇表 <span class="math inline">\(v\)</span> 中token的平均长度。</p><h3 id="preliminary-results">Preliminary Results</h3><p>为了验证 MUV 作为词汇化衡量标准的有效性，作者对来自 TED 的 45 个语言对进行了实验，并计算了 MUV 和 BLEU 分数之间的Spearman相关系数(<span class="math inline">\(\rho\)</span>)。Spearman 得分为 0.4。</p><blockquote><p>We believe that it is a good signal to show MUV matters</p></blockquote><p>有了MUV作为评价指标，我们有两个选择来获得最终词表：搜索和学习。作者认为基于学习是更高效的，因此进一步探索了一种基于学习的解决方案 VOLT。（当然最终借助实验比较了 MUV-Search 和 VOLT的性能。）</p><h2 id="maximizing-muv-via-optimal-transport">Maximizing MUV via Optimal Transport</h2><h3 id="优化问题">优化问题</h3><p>首先引入一个辅助变量<span class="math inline">\(S\)</span>，<span class="math inline">\(\boldsymbol{S}=\{k, 2 \cdot k, \ldots,(t-1) \cdot k, \cdots\}\)</span>。 <span class="math inline">\(S\)</span>是一个递增序列，对于每个时间戳t，<span class="math inline">\(S[t]\)</span>代表<strong>不多于<span class="math inline">\(S[t]\)</span>个词条的词表集合</strong>。引入这一变量，根据递推关系来计算任意一个词表的MUV（借助前一个时间戳s[t-1]上的词表递进计算）</p><p><span class="math inline">\(k\)</span>代表前后两个词表<span class="math inline">\(v(t)\)</span>和<span class="math inline">\(v(t-1)\)</span>之间的大小差（size gap）。我们的目标是找到MUV最高的<span class="math inline">\(v[t]\)</span> <span class="math display">\[\begin{array}{l}\underset{t}{\arg \max } \underset{v(t-1) \in \mathbb{V}_{\boldsymbol{S}[t-1]}, v(t) \in \mathbb{V}_{S[t]}}{\arg \max } \mathcal{M}_{v(t)}= \\\underset{t}{\arg \max } \underset{v(t-1) \in \mathbb{V}_{\boldsymbol{S}[t-1]}, v(t) \in \mathbb{V}_{S[t]}}{\arg \max }-\frac{1}{k}\left[\mathcal{H}_{v(t)}-\mathcal{H}_{v(t-1)}\right]\end{array}\]</span> <span class="math inline">\(\mathbb{V}_{\boldsymbol{S}[t-1]}\)</span>和 <span class="math inline">\(\mathbb{V}_{\boldsymbol{S}[t]}\)</span>表示两个词表的集合，其中每个词表大小的上界为<span class="math inline">\(s[t-1]\)</span>和<span class="math inline">\(s[t]\)</span></p><blockquote><p>The inner arg max represents that the target is to find the vocabulary from <span class="math inline">\(\mathbb{V}_{\boldsymbol{S}[t]}\)</span> with the maximum MUV scores. The outer arg max means that the target is to enumerate all timesteps and find the vocabulary with the maximum MUV scores.</p></blockquote><p>遍历t，遍历<span class="math inline">\(\mathbb{V}_{\boldsymbol{S}[t-1]}\)</span>。<br />（词表越大熵越小）上述公式意味着从v(t-1)这个词表，增加i个词/tokens之后，期望新得到的v(t)词表的熵降低的最多。即两个词表对应的熵的差值越大越好。</p><blockquote><p>Due to exponential search space, we propose to optimize its upper bound: <span class="math display">\[\underset{t}{\arg \max } \frac{1}{k}\left[\underset{v(t) \in \mathbb{V}_{S[t]}}{\arg \max } \mathcal{H}_{v(t)}-\underset{v(t-1) \in \mathbb{V}_{S[t-11}}{\arg \max } \mathcal{H}_{v(t-1)}\right]\]</span></p></blockquote><p>(论文ArXiv上的前一版本中写的还是lower bound...而最新版放的是upper bound...)<br />anyway至此整个方法可以分成两个步骤：</p><ul><li>每个时间步t上，寻找最优的词表（按照最大化熵来寻找）</li><li>枚举每个时间步t，并输出满足上一个公式的词表（对应的就是时间步t的”最优词表“）</li></ul><p>step1的目标就是最大化： <span class="math display">\[\underset{v(t) \in \mathbb{V}_{\boldsymbol{S}[t]}}{\arg \max }-\frac{1}{l_{v(t)}} \sum_{j \in v(t)} P(j) \log P(j)\]</span> <span class="math inline">\(l_{v}\)</span>是每个token的平均字符长度，<span class="math inline">\(P(j)\)</span>是token j的概率（频率）</p><blockquote><p>However, notice that this problem is in general intractable due to the extensive vocabulary size. Therefore, we instead propose a relaxation in the formulation of discrete optimal transport, which can then be solved efficiently via the Sinkhorn algorithm</p></blockquote><p>借助最优传输OT的思想，松弛原优化问题，进而用信息论中的Sinkhorn algorithm求解。</p><h3 id="optimal-transport-不太懂">Optimal Transport （不太懂）</h3><p><img src="/images/pd2_2.png" title="寻找一个从“character分布、单字分布”到“词表词条分布”的一个最优的运输矩阵的过程" /></p><ul><li>每个transport matrix对应一个词表；</li><li>transport matrix决定有多少chars被“运输”到token候选（词条候选）；</li><li>长度为0的tokens（包含0个chars)，不会被增加到词表。</li></ul><p>不同的”运输矩阵“会带来不同的”运输开销”。而最优化运输（路径）问题的目标就是寻找一个“运输矩阵“，使得”运输开销“(即，负熵)最小化。</p><p>目标函数： <span class="math display">\[\begin{array}{c}\min _{v \in \mathbb{V}_{S[t]}} \frac{1}{l_{v}} \sum_{j \in v} P(j) \log P(j) \\\text { s.t. } \quad P(j)=\frac{\operatorname{Token}(j)}{\sum_{j \in v} \operatorname{Token}(j)}, l_{v}=\frac{\sum_{j \in v} \operatorname{len}(j)}{|v|}\end{array}\]</span></p><p>近似(obtain a tractable lower bound of entropy) - 启发式规则(最长词条匹配原则) - 变换为两部分损失</p><p>复杂的推导后得到： <span class="math display">\[\min _{\boldsymbol{P} \in \mathbb{R}^{m \times n}}\langle\boldsymbol{P}, \boldsymbol{D}\rangle-\gamma H(\boldsymbol{P})\]</span></p><p><span class="math display">\[\boldsymbol{D}(j, i)=\left\{\begin{array}{ll}-\log P(i \mid j)=+\infty, &amp; \text { if } i \notin j \\-\log P(i \mid j)=-\log \frac{1}{\operatorname{len}(j)}, &amp; \text { otherwise }\end{array}\right.\]</span></p><p><img src="/images/pd2_4.png" title="算法（不太复杂）" /></p><h2 id="实验">实验</h2><p>3个数据集上NMT任务的BLEU比较（双语语料、多语语料等）<br />VOLT对比BPE、MUV search更加高效</p><p>最后，全论文的核心应该是MUV的提出以及用OT进行优化这一trick，实验结果也比较solid，虽然最终的算法并不复杂，但是OT部分Sinkhorn算法需要较强的信息论背景，本CS专业看了半年仍是一脸懵。<br />指路一篇介绍Sinkhorn算法的链接： <a href="https://arxiv.org/pdf/1803.00567.pdf" class="uri">https://arxiv.org/pdf/1803.00567.pdf</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2012.15671.pdf&quot;&gt;Vocabulary Learning via Optimal Transport for Neural Machine Translation&lt;/a&gt;&lt;br /&gt;
ACL2021</summary>
      
    
    
    
    <category term="Paper_daily" scheme="http://example.com/categories/Paper-daily/"/>
    
    
    <category term="ACL2021" scheme="http://example.com/tags/ACL2021/"/>
    
  </entry>
  
  <entry>
    <title>Encoding Word Order in Complex Embeddings [ICLR2020]</title>
    <link href="http://example.com/2021/10/09/p1-position-encoding/"/>
    <id>http://example.com/2021/10/09/p1-position-encoding/</id>
    <published>2021-10-09T13:29:54.000Z</published>
    <updated>2021-10-26T15:36:04.658Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1912.12333.pdf">Encoding Word Order in Complex Embeddings</a><br />Code: <a href="https://github.com/iclr-complex-order/complex-order">link</a></p><h2 id="概要">概要</h2><p>针对位置编码提出的改进，切入点新颖高效且为位置编码带来了一定的具体意义和可解释性。传统的位置嵌入捕获单个单词的位置，而不是单个单词位置之间的有序关系(例如邻接关系或优先级)。本文提出的方法建模单词的全局绝对位置和它们的顺序关系，将以前定义为独立向量的词嵌入推广到变量(位置)上的连续词函数。每个单词的表示会随着位置的增加而移动。因此，在连续函数中，不同位置的词表示可以相互关联。将这些函数的通解推广到复值域，得到了更丰富的表示。作者在文本分类、机器翻译和语言模型方面进行实验，取得了良好的表现。</p><h2 id="positional-encoding">Positional encoding</h2><p>Positional encoding 位置编码在transformer中用于存储位置信息（由于self-attention没法获取序列位置的信息），此外BERT中encoding部分也包含了位置编码。对于位置编码，本能的想法是针对序列中的每个位置必须是独一无二的，且不受序列长度的影响。常见的positional encoding的方法有:</p><ul><li>绝对（正弦）位置编码（Sinusoidal Position Encoding）</li><li>相对位置编码（Relative Position Representations）</li><li>可学习位置编码</li></ul><h3 id="正弦位置编码">正弦位置编码</h3><p>Transformer中使用的就是这种编码，实际上具体编码过程使用了正弦和余弦。具体公式为： <span class="math display">\[\begin{aligned}P E_{(p o s, 2 i)} &amp;=\sin \left(p o s / 10000^{2 i / d_{\text {model }}} \right) \\P E_{(p o s, 2 i+1)} &amp;=\cos \left(p o s / 10000^{2 i / d_{\text {model }}} \right)\end{aligned}\]</span> 其中<span class="math inline">\(d_{model}\)</span>为输入词向量的维度。如d(model)=128,那么位置3对应的位置向量为 <span class="math display">\[\left[\sin \left(3 / 10000^{0 / 128}\right), \cos \left(3 / 10000^{1 / 128}\right), \sin \left(3 / 10000^{2 / 28}\right), \cos \left(3 / 10000^{3 / 28}\right), \ldots\right]\]</span> 在具体的应用时可能前一部分用正弦后一部分用余弦。</p><p><img src="/images/pe4.png" title="Bert中的位置编码" /></p><h3 id="相对位置编码">相对位置编码</h3><p>Todo<br /><a href="https://arxiv.org/abs/1803.02155">Self-Attention with Relative Position Representations</a></p><h3 id="可学习位置编码">可学习位置编码</h3><p>Todo</p><h2 id="intro">Intro</h2><p>本文的重点在于建模文本信息中额外的词的内部顺序和相邻关系，对比原本位置编码方式仅编码词的位置。模型将之前定义为独立向量的词嵌入扩展为位置自变量上的连续函数。在一个连续函数中，不同位置的词表示可以相互关联。</p><p><img src="/images/pe1.png" /></p><h2 id="methodology">Methodology</h2><p>类似于Word Embedding，位置编码（PE）定义了一个映射关系，将词的序列索引映射为一个向量。<span class="math inline">\(f_{n e}: \mathbb{N} \rightarrow \mathbb{R}^{D}\)</span>。最终某个词的embedding通常表示为为词向量和位置向量的和： <span class="math display">\[f(j, p o s)=f_{w e}(j)+f_{p e}(p o s)\]</span></p><p>论文中提出了一个位置独立问题（position independence problem），即位置编码无法捕获相邻词以及其顺序之间的潜在关系。而当后续用于特征处理的网络对这类信息不敏感时，这一问题就会限制整个模型的表达能力。相对位置编码针对这一问题进行了一定的研究，但其无法涵盖整个序列域。</p><h3 id="性质">性质</h3><p>论文指出了在位置编码中建立词序模型所必需的性质。<br />由于位置向量中每个维度的值都是根据离散的位置index得到的，这使得位置间有序关系建模变得困难，因此需要根据位置索引构建一个连续的函数（以在每个维度中表示一个特定的单词？） <span class="math display">\[f(j, \text { pos })=\boldsymbol{g}_{j}(\text { pos }) \in \mathbb{R}^{D}\]</span> <span class="math inline">\(g_j\)</span>即<span class="math inline">\(\boldsymbol{g}_{w e}(j) \in(\mathcal{F})^{D}\)</span>，词<span class="math inline">\(w_j\)</span>在pos位置可以表示为 <span class="math display">\[\left[g_{j, 1}(\operatorname{pos}), g_{j, 2}(\operatorname{pos}), \ldots, g_{j, D}(\text { pos })\right] \in \mathbb{R}^{D}\]</span> 当词<span class="math inline">\(w_j\)</span>从pos位置转到pos’位置时，只需要改变自变量的值而不需要改变映射函数<span class="math inline">\(g_j\)</span>。</p><h3 id="函数">函数</h3><p>由于实数也被囊括在复数域中，且前人有相关工作（详见论文原文Section2.2）验证了复数域所具有的更强大的表达能力，作者将模型拓展到了复数域。对于理想的映射函数，论文中提出了两条性质，即:</p><ul><li>Position-free offset transformation</li><li>Boundedness</li></ul><p>变换函数<span class="math inline">\(Transform\)</span>需满足对于任何pos，有 <span class="math display">\[g(p o s+n)=\operatorname{Transform}_{n}(g(p o s))\]</span> 满足等式的变换函数被称为witness，而满足这一条件的映射函数<span class="math inline">\(g_j\)</span>则被称为<em>linearly witnessed</em>。规定Transform <span class="math inline">\((n\)</span>, pos <span class="math inline">\()=\)</span> Transform <span class="math inline">\(_{n}(\)</span> pos <span class="math inline">\()=w(n)\)</span>。另外，映射函数<span class="math inline">\(g_j\)</span>需要有界。</p><p>而后作者证明了满足上述性质的映射函数唯一解为 <span class="math display">\[g(p o s)=z_{2} z_{1}^{p o s} \text { for } z_{1}, z_{2} \in \mathbb{C} \text { with }\left|z_{1}\right| \leq 1\]</span> 对于任意的 <span class="math inline">\(z \in \mathbb{C}\)</span>, 我们可以写成 <span class="math inline">\(z=r e^{i \theta}=r(\cos \theta+i \sin \theta)\)</span>，因此上式可写为： <span class="math display">\[g(p o s)=z_{2} z_{1}^{p o s}=r_{2} e^{i \theta_{2}}\left(r_{1} e^{i \theta_{1}}\right)^{p o s}=r_{2} r_{1}^{p o s} e^{i\left(\theta_{2}+\theta_{1} p o s\right)} \quad$ subject to $\left|r_{1}\right| \leq 1\]</span></p><p>(...跳过证明和优化过程)</p><p>最终的位置编码函数<span class="math inline">\(f(j\)</span>, pos <span class="math inline">\()\)</span>为 <img src="/images/pe2.png" /> <span class="math inline">\(j\)</span>代表单词（索引），<span class="math inline">\(pos\)</span>表示位置索引。<br />对于embedding中的每一维度，都有各自的参数，振幅r、频率p、初相<span class="math inline">\(\theta\)</span>，这些参数是trainable的。此外，周期/频率决定了单词对位置的敏感程度。当周期很短，则说明嵌入将对position高度敏感。注意，振幅、频率是与postion（自变量）无关的，与单词和维度有关。此时，word embedding可以用这些参数来表示（维度与positional embedding维度相同）。</p><h2 id="实验">实验</h2><p>作者在文本分类、机器翻译和语言模型几个任务上进行了实验，分别用Fasttext、LSTM、CNN、Transformer作为模型的backbone，而后使用不同的位置编码方法以及本文的Complex-order编码方法进行embedding，对比几个实验结果均取得了可观的提升。而计算开销（时间）上并没有显著的增加。 <img src="/images/pe3.png" title="部分实验结果" /> 实验基于tensorflow，目前没有pytorch版本，笔者将会尝试将其迁移到pytorch框架下并开源。</p><h2 id="相关工作">相关工作</h2><p>Vanilla Position Embeddings<br />Trigonometric Position Embeddings<br />Todo</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1912.12333.pdf&quot;&gt;Encoding Word Order in Complex Embeddings&lt;/a&gt;&lt;br /&gt;
Code: &lt;a href=&quot;https://github.com/iclr</summary>
      
    
    
    
    <category term="Paper_daily" scheme="http://example.com/categories/Paper-daily/"/>
    
    
    <category term="Positional_encoding" scheme="http://example.com/tags/Positional-encoding/"/>
    
  </entry>
  
  <entry>
    <title>Improved GCN for Text Classification [GNN]</title>
    <link href="http://example.com/2021/09/29/textGCN/"/>
    <id>http://example.com/2021/09/29/textGCN/</id>
    <published>2021-09-29T14:24:53.000Z</published>
    <updated>2021-09-30T16:45:05.204Z</updated>
    
    <content type="html"><![CDATA[<center><font size = 4> <strong>TextRGNN: Residual Graph Neural Networks for Text Classification</strong></font></center>]]></content>
    
    
      
      
    <summary type="html">&lt;center&gt;
&lt;font size = 4&gt; &lt;strong&gt;TextRGNN: Residual Graph Neural Networks for Text Classification&lt;/strong&gt;&lt;/font&gt;
&lt;/center&gt;
</summary>
      
    
    
    
    <category term="Research" scheme="http://example.com/categories/Research/"/>
    
    
    <category term="TextGCN" scheme="http://example.com/tags/TextGCN/"/>
    
  </entry>
  
  <entry>
    <title>word2vec</title>
    <link href="http://example.com/2021/09/29/word2vec/"/>
    <id>http://example.com/2021/09/29/word2vec/</id>
    <published>2021-09-28T16:10:00.000Z</published>
    <updated>2021-09-28T16:10:08.351Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>sort algorithm 1</title>
    <link href="http://example.com/2021/09/20/sort-1/"/>
    <id>http://example.com/2021/09/20/sort-1/</id>
    <published>2021-09-20T15:01:57.000Z</published>
    <updated>2021-09-28T16:05:07.653Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sorti">Sort(i)</h1><p>三种复杂度为<span class="math inline">\(O(n^2)\)</span>的排序算法:</p><ul><li>冒泡排序</li><li>选择排序</li><li>插入排序</li></ul><h2 id="bubble-sort">Bubble sort</h2><p>“一趟一趟来” <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span>(<span class="params">ls</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-i-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> ls[j] &gt; ls[j+<span class="number">1</span>]:</span><br><span class="line">                ls[j+<span class="number">1</span>],ls[j]=ls[j],ls[j+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span>(ls)</span><br></pre></td></tr></table></figure></p><h2 id="select-sort">Select sort</h2><p>&quot;一个一个排&quot; <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_sort</span>(<span class="params">ls</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-<span class="number">1</span>):</span><br><span class="line">        min_loc = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ls)-<span class="number">1</span>-i):</span><br><span class="line">            <span class="keyword">if</span> ls[i+j]&lt;ls[min_loc]:</span><br><span class="line">                min_loc =i+j</span><br><span class="line">        ls[min_loc],ls[i] = ls[i],ls[min_loc]</span><br><span class="line">    <span class="built_in">print</span>(ls)</span><br></pre></td></tr></table></figure></p><h2 id="insert-sort">Insert sort</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_select</span>(<span class="params">ls</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(ls)):</span><br><span class="line">        j = i-<span class="number">1</span></span><br><span class="line">        tmp = ls[i]</span><br><span class="line">        <span class="keyword">while</span> j&gt;=<span class="number">0</span> <span class="keyword">and</span> ls[j]&gt;tmp:</span><br><span class="line">            ls[j+<span class="number">1</span>]=ls[j]</span><br><span class="line">            j-=<span class="number">1</span></span><br><span class="line">        ls[j+<span class="number">1</span>] = tmp</span><br><span class="line">    <span class="built_in">print</span>(ls)</span><br></pre></td></tr></table></figure><h1 id="sortii">Sort(ii)</h1><p>三种复杂度为<span class="math inline">\(O(nlogn)\)</span>的排序算法:</p><ul><li>快速排序</li><li>归并排序</li><li>堆排序</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;sorti&quot;&gt;Sort(i)&lt;/h1&gt;
&lt;p&gt;三种复杂度为&lt;span class=&quot;math inline&quot;&gt;\(O(n^2)\)&lt;/span&gt;的排序算法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;冒泡排序&lt;/li&gt;
&lt;li&gt;选择排序&lt;/li&gt;
&lt;li&gt;插入排序&lt;/li&gt;
&lt;/</summary>
      
    
    
    
    <category term="Leetcode" scheme="http://example.com/categories/Leetcode/"/>
    
    
    <category term="Data Structure" scheme="http://example.com/tags/Data-Structure/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression (python &amp; pytorch)</title>
    <link href="http://example.com/2021/08/25/dae%E7%9A%84%E5%89%AF%E6%9C%AC/"/>
    <id>http://example.com/2021/08/25/dae%E7%9A%84%E5%89%AF%E6%9C%AC/</id>
    <published>2021-08-25T15:21:47.000Z</published>
    <updated>2021-09-28T16:09:28.897Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    <category term="Preliminary AI" scheme="http://example.com/categories/Preliminary-AI/"/>
    
    
    <category term="ML" scheme="http://example.com/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>search algorithm</title>
    <link href="http://example.com/2021/08/25/test/"/>
    <id>http://example.com/2021/08/25/test/</id>
    <published>2021-08-25T14:42:55.000Z</published>
    <updated>2021-09-28T15:52:31.772Z</updated>
    
    <content type="html"><![CDATA[<h1 id="linear-search-and-binary-search">Linear Search and Binary Search</h1><h2 id="linear-search">Linear search</h2><p>Time complexity：<span class="math inline">\(O(n)\)</span> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_search</span>(<span class="params">ls,val</span>):</span></span><br><span class="line">    <span class="keyword">for</span> index,value <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        <span class="keyword">if</span> value == val:</span><br><span class="line">            <span class="keyword">return</span> index</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></p><h2 id="binary-search">Binary search</h2><p>Time complexity：<span class="math inline">\(O(log n)\)</span> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">ls,val</span>):</span></span><br><span class="line">    left = <span class="number">0</span>  <span class="comment">#左指针</span></span><br><span class="line">    right = <span class="built_in">len</span>(ls)-<span class="number">1</span>  <span class="comment">#右指针</span></span><br><span class="line">    <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">        mid = (left+right)//<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> ls[mid] == val:</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        <span class="keyword">elif</span> ls[mid]&lt;val:</span><br><span class="line">            left = mid+<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right = mid-<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;linear-search-and-binary-search&quot;&gt;Linear Search and Binary Search&lt;/h1&gt;
&lt;h2 id=&quot;linear-search&quot;&gt;Linear search&lt;/h2&gt;
&lt;p&gt;Time complexity：&lt;</summary>
      
    
    
    
    <category term="Leetcode" scheme="http://example.com/categories/Leetcode/"/>
    
    
    <category term="Data Structure" scheme="http://example.com/tags/Data-Structure/"/>
    
  </entry>
  
  <entry>
    <title>BERT</title>
    <link href="http://example.com/2021/08/16/test-my-site/"/>
    <id>http://example.com/2021/08/16/test-my-site/</id>
    <published>2021-08-16T14:58:35.000Z</published>
    <updated>2021-09-29T14:29:21.109Z</updated>
    
    <content type="html"><![CDATA[<h1 id="pre-training-of-deep-bidirectional-transformers-for-language-understanding">Pre-training of Deep Bidirectional Transformers for Language Understanding</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;pre-training-of-deep-bidirectional-transformers-for-language-understanding&quot;&gt;Pre-training of Deep Bidirectional Transformers for Lang</summary>
      
    
    
    
    <category term="Paper_daily" scheme="http://example.com/categories/Paper-daily/"/>
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Markdown语法</title>
    <link href="http://example.com/2021/08/16/hello-world/"/>
    <id>http://example.com/2021/08/16/hello-world/</id>
    <published>2021-08-16T14:25:40.470Z</published>
    <updated>2021-09-30T16:42:47.024Z</updated>
    
    <content type="html"><![CDATA[<p>由于Hexo博客的撰写需要用Markdown，虽然比Latex要简单点，但是平时用的比较少，这些杂七杂八的语法很难一下子全部记住，因此在这页博客中记录一下</p><h2 id="文字">文字</h2><h3 id="标题">标题</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="居中">居中</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;center&gt;这一行需要居中&lt;/center&gt;</span><br></pre></td></tr></table></figure><h3 id="字体">字体</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">**（）** 加粗</span><br><span class="line">*（）* 斜体</span><br><span class="line">～～（）～～ 删除线</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;font face= “黑体” color=red size=7&gt;字体设置&lt;/font&gt; #size 1-7，浏览器默认3</span><br></pre></td></tr></table></figure><h2 id="引用">引用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;这是引用文字</span><br></pre></td></tr></table></figure><h2 id="分割线">分割线</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">***</span><br></pre></td></tr></table></figure><h2 id="图片">图片</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![图片alt](图片地址 &#x27;&#x27;图片title&#x27;&#x27;)</span><br></pre></td></tr></table></figure><p>图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加</p><h2 id="链接">链接</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[超链接名](超链接地址 &quot;超链接title&quot;)</span><br></pre></td></tr></table></figure><h2 id="列表">列表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 列表内容</span><br><span class="line">+ 列表内容</span><br><span class="line">1. 列表内容</span><br></pre></td></tr></table></figure><h2 id="代码">代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">`代码内容`</span><br><span class="line">\``` (防止打不出加个\转义一下)</span><br><span class="line">  代码...</span><br><span class="line">  代码...</span><br><span class="line">  代码...</span><br><span class="line">\```</span><br></pre></td></tr></table></figure><h2 id="数学公式">数学公式</h2><p>公式、希腊字母、上标下标等基本语法与latex类似，可参考<a href="https://www.jianshu.com/p/a0aa94ef8ab2">markdown数学公式</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">正文中$...$</span><br><span class="line">单行显示$$...$$</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于Hexo博客的撰写需要用Markdown，虽然比Latex要简单点，但是平时用的比较少，这些杂七杂八的语法很难一下子全部记住，因此在这页博客中记录一下&lt;/p&gt;
&lt;h2 id=&quot;文字&quot;&gt;文字&lt;/h2&gt;
&lt;h3 id=&quot;标题&quot;&gt;标题&lt;/h3&gt;
&lt;figure class=&quot;</summary>
      
    
    
    
    <category term="杂七杂八" scheme="http://example.com/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>漫威人物知识图谱-MARVEL Knowledge Graph</title>
    <link href="http://example.com/2021/05/24/kg/"/>
    <id>http://example.com/2021/05/24/kg/</id>
    <published>2021-05-24T10:16:44.000Z</published>
    <updated>2021-10-24T10:23:21.267Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    
      
      
    <summary type="html">
</summary>
      
    
    
    
    <category term="Project" scheme="http://example.com/categories/Project/"/>
    
    
    <category term="KG" scheme="http://example.com/tags/KG/"/>
    
  </entry>
  
  <entry>
    <title>DAE for Action Quality Assessment(AQA)  [CV]</title>
    <link href="http://example.com/2020/09/25/dae/"/>
    <id>http://example.com/2020/09/25/dae/</id>
    <published>2020-09-25T15:21:47.000Z</published>
    <updated>2021-09-30T16:41:07.071Z</updated>
    
    <content type="html"><![CDATA[<p><font  size=5>Auto-Encoding Score Distribution Regression for Action Quality Assessment</font></p><p><em>Action quality assessment (AQA) from videos is a challenging vision task since the relation between videos and action scores is difficult to model. Thus, action quality assessment has been widely studied in the literature. Traditionally, AQA task is treated as a regression problem to learn the underlying mappings between videos and action scores. More recently, the method of uncertainty score distribution learning (USDL) made success due to the introduction of label distribution learning (LDL). But USDL does not apply to dataset with continuous labels and needs a fixed variance in training. In this paper, to address the above problems, we further develop Distribution Auto-Encoder (DAE). DAE takes both advantages of regression algorithms and label distribution learning (LDL). Specifically, it encodes videos into distributions and uses the reparameterization trick in variational auto-encoders (VAE) to sample scores, which establishes a more accurate mapping between videos and scores. Meanwhile, a combined loss is constructed to accelerate the training of DAE. DAE-MT is further proposed to deal with AQA on multi-task datasets. We evaluate our DAE approach on MTL-AQA and JIGSAWS datasets. Experimental results on public datasets demonstrate that our method achieves state-of- the-arts under the Spearman’s Rank Correlation: 0.9449 on MTL-AQA and 0.73 on JIGSAWS.</em></p><h2 id="aqa">AQA</h2><p>Action Quality Accessment (AQA) automatically scores the quality of actions by analyzing features extracted from videos and images. It’s different from conventional action recognition problem. In the past few years, much work has been devoted to different AQA tasks, such as healthcare, sports video analysis and many others.</p><h2 id="related-work">Related Work</h2><p>Parmar <em>et al.</em> [1] proposed C3D-SVR and C3D-LSTM to predict the score of the Olympic events. Additionally, incremental-label training method was introduced to train the LSTM model based on the hypothesis that the final score is an aggregation of the sequential sub-action scores.</p><p>Tang <em>et al.</em> noticed the underlying ambiguity of action scores and then proposed an improved approach: uncertainty-aware score distribution learning (USDL) [2] to address this problem. USDL is designed based on label distribution learning (LDL), a general learning paradigm to solve problems with uncertainty and answer how much each label describes the instance.</p><h2 id="methoddae">Method:DAE</h2><p><img src="/images/dae1.png" title="The pipeline of DAE architecture contains two segments: video features extraction network (orange) and label distribution encoding network (pink)." /></p><h3 id="video-feature-extraction">Video Feature Extraction</h3><p>The input video is divided into n small clips by down-sampling. Then the clips are sent into I3D ConvNets for extracting features. The final features are synthesized by three fully-connected layers.</p><h3 id="auto-encoder-for-distribution-learning">Auto-Encoder for Distribution Learning</h3><p>Compared with the regression-based method and the label distribution learning method, our approach combines the two methods’ characteristics comprehensively. The action features are encoded into score distribution, and the final result is sampled from the auto-encoders output. This architecture en- ables learning a continuous distribution without loss in training procedure and quantifies the uncertainty of action score with high accuracy.</p><p>The encoder uses a simple but quite an efficient neural network, namely multi-layered perceptrons (MLPs), to encode mean and variance simultaneously. The input 1024-dimensional feature vector x is encoded into the parameters <span class="math inline">\(μ(x)\)</span> and <span class="math inline">\(σ^2(x)\)</span> via a neural network.</p><p>We take the action score as a random variable. Treating the action score as a random variable, we need to learn its score distribution and then sample the predicted score from the obtained distribution. <span class="math display">\[p\left(y ; \mu(\boldsymbol{x}), \sigma^{2}(\boldsymbol{x})\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}(\boldsymbol{x})}} \exp \left(-\frac{(y-\mu(\boldsymbol{x}))^{2}}{2 \sigma^{2}(\boldsymbol{x})}\right)\]</span></p><p>To generate a sample from Gaussian distributed y as the predicted score and make full use of the two parameters in the score distribution at the same time, we invoke the reparameterization trick. According to reparameterization trick in VAE [3], assume that <span class="math inline">\(z\)</span> is a random variable, and <span class="math inline">\(z \sim q(z ; \phi), \phi\)</span> is its parameter. We can express <span class="math inline">\(z\)</span> as a deterministic variable, <span class="math inline">\(z=g(\epsilon ; \phi), \epsilon\)</span> is an auxiliary variable with independent marginal <span class="math inline">\(p(\epsilon)\)</span>, and <span class="math inline">\(g(\cdot ; \phi)\)</span> is a deterministic function parameterized by <span class="math inline">\(\phi\)</span>.<br /><span class="math display">\[y=\mu(\boldsymbol{x})+\epsilon * \sigma^{2}(\boldsymbol{x})\]</span></p><h2 id="experiments">Experiments</h2><p>We use Spearman’s rank correlation to measure the performance of our methods between the ground-truth and predicted score series. Spearman’s correlation is defined as: <span class="math display">\[\rho=\frac{\sum_{i}\left(p_{i}-\bar{p}\right)\left(q_{i}-\bar{q}\right)}{\sqrt{\sum_{i}\left(p_{i}-\bar{p}\right)^{2} \sum_{i}\left(q_{i}-\bar{q}\right)^{2}}}\]</span> <img src="/images/dae2.png" title="The results on JIGSAWS." /> <img src="/images/dae3.png" title="The results on MTL-AQA." /></p><p><img src="/images/dae4.png" title="Comparison of different distribution of different videos on MTL-AQA dataset." /></p><p>References (incomplete)<br />[1] What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment<br />[2] Uncertainty-aware score distribution learning for action quality assessment<br />[3] Auto-encoding variational bayes</p><p>Cooperate with zby (seu) supervisor: xyf (seu)<br /><a href="https://github.com/InfoX-SEU/DAE-AQA">Github link</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;font  size=5&gt;Auto-Encoding Score Distribution Regression for Action Quality Assessment&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Action quality assessment (AQA)</summary>
      
    
    
    
    <category term="Research" scheme="http://example.com/categories/Research/"/>
    
    
    <category term="AQA" scheme="http://example.com/tags/AQA/"/>
    
  </entry>
  
</feed>
